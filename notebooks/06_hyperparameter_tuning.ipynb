{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faee596b",
   "metadata": {},
   "source": [
    "# **6. Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f05ce147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_reduced = pd.read_csv(\"../data/heart_reduced.csv\")\n",
    "X_reduced = df_reduced.drop(columns='num')\n",
    "y = df_reduced['num'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e0676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "sco = {\"accuracy\": \"accuracy\", \"f1\": \"f1\", \"recall\": \"recall\", \"precision\": \"precision\"}\n",
    "\n",
    "\n",
    "def summarize_best(search, name):\n",
    "    print(f\"{name} best params:\", search.best_params_)\n",
    "    print(f\"{name} best CV AUC: {search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a089ad2",
   "metadata": {},
   "source": [
    "**5.1 Logistic Regression (GridSearchCV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d314a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg best params: {'clf__C': 0.1, 'clf__penalty': 'l1', 'fs__k': 9}\n",
      "LogReg best CV AUC: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Menna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "log_pipe = Pipeline(steps=[\n",
    "    (\"fs\", SelectKBest(mutual_info_classif, k=\"all\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver=\"liblinear\", class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "log_grid = {\n",
    "    \"fs__k\": [min(10, X_reduced.shape[1]), \"all\"],\n",
    "    \"clf__penalty\": [\"l1\", \"l2\"],\n",
    "    \"clf__C\": [0.1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "log_search = GridSearchCV(log_pipe, param_grid=log_grid, scoring=sco, refit='f1', cv=cv, n_jobs=-1)\n",
    "log_search.fit(X_train, y_train)\n",
    "summarize_best(log_search, \"LogReg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf67397",
   "metadata": {},
   "source": [
    "**5.2 Decision tree (GridSearchCV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de0b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree best params: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree best CV AUC: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Menna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_grid = {\n",
    "    \"max_depth\": [None, 3, 5, 7, 10],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "dt_search = GridSearchCV(DecisionTreeClassifier(class_weight=\"balanced\", random_state=42),\n",
    "                         param_grid=dt_grid, scoring=sco, refit=\"f1\", cv=cv, n_jobs=-1)\n",
    "dt_search.fit(X_train, y_train)\n",
    "summarize_best(dt_search, \"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73173684",
   "metadata": {},
   "source": [
    "**5.3 Random forest (RandomizedSearchCV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd324a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Menna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest best params: {'max_depth': 12, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 14, 'n_estimators': 320}\n",
      "RandomForest best CV AUC: nan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "rf_dist = {\n",
    "    \"n_estimators\": randint(300, 800),\n",
    "    \"max_depth\": [None] + list(range(4, 18, 4)),\n",
    "    \"min_samples_split\": randint(2, 16),\n",
    "    \"min_samples_leaf\": randint(1, 10),\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=42),\n",
    "    param_distributions=rf_dist,\n",
    "    n_iter=50, scoring=sco, refit= \"f1\", cv=cv, n_jobs=-1, random_state=42\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "summarize_best(rf_search, \"RandomForest\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa23391d",
   "metadata": {},
   "source": [
    "**5.4 SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9236071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM best params: {'clf__C': 0.5, 'clf__gamma': 'scale', 'clf__kernel': 'rbf', 'pca': PCA(n_components=0.95)}\n",
      "SVM best CV AUC: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Menna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "svm_pipe = Pipeline(steps=[\n",
    "    (\"pca\", PCA(n_components=0.95)),\n",
    "    (\"clf\", SVC(probability=True, class_weight=\"balanced\", random_state=42))\n",
    "])\n",
    "\n",
    "svm_grid = {\n",
    "    \"pca\": [PCA(n_components=0.95), \"passthrough\"],\n",
    "    \"clf__kernel\": [\"rbf\", \"linear\"],\n",
    "    \"clf__C\": [0.5, 1, 5, 10],\n",
    "    \"clf__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "svm_search = GridSearchCV(svm_pipe, param_grid=svm_grid, scoring=sco, refit=\"f1\", cv=cv, n_jobs=-1)\n",
    "svm_search.fit(X_train, y_train)\n",
    "summarize_best(svm_search, \"SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ee587",
   "metadata": {},
   "source": [
    "**Compare optimized models on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27d17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Accuracy  Precision    Recall        F1\n",
      "Model                                                \n",
      "LogReg        0.783333   0.827917  0.783333  0.804195\n",
      "DecisionTree  0.833333   0.808642  0.833333  0.815629\n",
      "RandomForest  0.733333   0.833398  0.733333  0.777250\n",
      "SVM           0.700000   0.874231  0.700000  0.763171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_models = {\n",
    "    \"LogReg\": log_search.best_estimator_,\n",
    "    \"DecisionTree\": dt_search.best_estimator_,\n",
    "    \"RandomForest\": rf_search.best_estimator_,\n",
    "    \"SVM\": svm_search.best_estimator_\n",
    "}\n",
    "\n",
    "tuned_results = []\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    tuned_results.append([name, acc, prec, rec, f1]) \n",
    "\n",
    "\n",
    "tuned_df = pd.DataFrame(tuned_results, columns=[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1\"]).set_index(\"Model\") # Updated columns\n",
    "print(tuned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a1e0d",
   "metadata": {},
   "source": [
    "# Persist best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb0a6a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best tuned model: DecisionTree\n",
      "Best model saved to models/final_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_name = tuned_df[\"F1\"].idxmax()\n",
    "final_model = log_search.best_estimator_\n",
    "print(\"Best tuned model:\", best_name)\n",
    "\n",
    "joblib.dump(final_model, \"../models/final_pipeline.pkl\")\n",
    "\n",
    "print(\"Best model saved to models/final_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "370075aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('fs',\n",
      "                 SelectKBest(k=9,\n",
      "                             score_func=<function mutual_info_classif at 0x00000145B5381DA0>)),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=0.1, class_weight='balanced',\n",
      "                                    max_iter=1000, penalty='l1',\n",
      "                                    solver='liblinear'))])\n"
     ]
    }
   ],
   "source": [
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3683f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2\n",
      "Probabilities: [0.17073364 0.41394175 0.41532461]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Menna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but SelectKBest was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Menna\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but SelectKBest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "model = joblib.load(\"../models/final_pipeline.pkl\")\n",
    "\n",
    "input_array = np.array([[1, 2.3, 1, 0, 150, 0, 2, 2, 3]])\n",
    "\n",
    "prediction = model.predict(input_array)[0]\n",
    "proba = model.predict_proba(input_array)[0] \n",
    "print(\"Prediction:\", prediction)     \n",
    "print(\"Probabilities:\", proba)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "992b3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n",
      "Macro F1-score: 0.42\n",
      "Weighted F1-score: 0.8\n",
      "\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "   Class 0 (No disease)       0.94      0.90      0.92        50\n",
      "     Class 1 (Low risk)       0.40      0.29      0.33         7\n",
      "Class 2 (Moderate risk)       0.00      0.00      0.00         3\n",
      "\n",
      "               accuracy                           0.78        60\n",
      "              macro avg       0.45      0.40      0.42        60\n",
      "           weighted avg       0.83      0.78      0.80        60\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[45  2  3]\n",
      " [ 1  2  4]\n",
      " [ 2  1  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Overall metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "weighted_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", round(accuracy, 2))\n",
    "print(\"Macro F1-score:\", round(macro_f1, 2))\n",
    "print(\"Weighted F1-score:\", round(weighted_f1, 2))\n",
    "\n",
    "# Per-class metrics\n",
    "report = classification_report(y_test, y_pred, target_names=[\n",
    "    \"Class 0 (No disease)\",\n",
    "    \"Class 1 (Low risk)\",\n",
    "    \"Class 2 (Moderate risk)\"\n",
    "])\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
